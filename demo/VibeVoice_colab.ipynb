{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "AHLptWHtQmw-",
      "metadata": {
        "id": "AHLptWHtQmw-"
      },
      "source": [
        "# VibeVoice Colab — T4 Quickstart (1.5B)\n",
        "This page provides a quickstart guide to run VibeVoice on Colab with T4.\n",
        "\n",
        "The T4 GPU can only support the 1.5B model due to memory limitations. Please note that T4 can only use SDPA instead of flash_attention_2, which may result in unstable and lower audio quality. For the best TTS experience, we recommend trying the 7B model on a more powerful GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vzwhx5AtQ37g",
      "metadata": {
        "id": "vzwhx5AtQ37g"
      },
      "source": [
        "## Step 1: Use T4\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ryxffqxlVbbP",
      "metadata": {
        "id": "ryxffqxlVbbP"
      },
      "source": [
        "Use T4 in Colab: go to Runtime → Change runtime type → Hardware accelerator: GPU → T4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hek0yZKdVot_",
      "metadata": {
        "id": "Hek0yZKdVot_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S8D9WNSvWFwy",
      "metadata": {
        "id": "S8D9WNSvWFwy"
      },
      "source": [
        "## Step 2: Env Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2xGbc7gKMD7A",
      "metadata": {
        "id": "2xGbc7gKMD7A"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/microsoft/VibeVoice.git\n",
        "\n",
        "import os\n",
        "os.chdir(\"./VibeVoice\")\n",
        "\n",
        "!apt update && apt install ffmpeg -y && pip install modelscope\n",
        "!pip install -e .\n",
        "\n",
        "from modelscope import snapshot_download\n",
        "# snapshot_download('ByteDance/Dolphin', local_dir='pretrained_models/Dolphin')\n",
        "\n",
        "snapshot_download('microsoft/VibeVoice-1.5B', local_dir='pretrained_models/VibeVoice-1.5B')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YmxjRFSFW4aE",
      "metadata": {
        "id": "YmxjRFSFW4aE"
      },
      "source": [
        "## Step 3: Run VibeVoice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MfQ0geOJQNS5",
      "metadata": {
        "id": "MfQ0geOJQNS5"
      },
      "outputs": [],
      "source": [
        "# First download checkpoint takes ~3 minutes\n",
        "!python demo/inference_from_file.py --model_path microsoft/VibeVoice-1.5B --txt_path demo/text_examples/2p_short.txt --speaker_names Alice Frank\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(\"./outputs/2p_short_generated.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pd6-KX2Hdswx",
      "metadata": {
        "id": "Pd6-KX2Hdswx"
      },
      "source": [
        "### TTS from your text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZB482MvXbg8M",
      "metadata": {
        "id": "ZB482MvXbg8M"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Speaker 1: Can I try VibeVoice with my own example?\n",
        "Speaker 2: Of course! VibeVoice is open-source, built to benefit everyone — you’re welcome to try it out.\"\"\"\n",
        "with open(\"demo/text_examples/my_example.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "heoxL08yM-gf",
      "metadata": {
        "id": "heoxL08yM-gf"
      },
      "outputs": [],
      "source": [
        "!python demo/inference_from_file.py --model_path microsoft/VibeVoice-1.5B --txt_path demo/text_examples/my_example.txt --speaker_names Alice Frank\n",
        "Audio(\"./outputs/my_example_generated.wav\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f09ff159",
      "metadata": {},
      "source": [
        "# Risk and Limitations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e15d4e0",
      "metadata": {},
      "source": [
        "While efforts have been made to optimize it through various techniques, it may still produce outputs that are unexpected, biased, or inaccurate. VibeVoice inherits any biases, errors, or omissions produced by its base model (specifically, Qwen2.5 1.5b in this release). Potential for Deepfakes and Disinformation: High-quality synthetic speech can be misused to create convincing fake audio content for impersonation, fraud, or spreading disinformation. Users must ensure transcripts are reliable, check content accuracy, and avoid using generated content in misleading ways. Users are expected to use the generated content and to deploy the models in a lawful manner, in full compliance with all applicable laws and regulations in the relevant jurisdictions. It is best practice to disclose the use of AI when sharing AI-generated content."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vv311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
